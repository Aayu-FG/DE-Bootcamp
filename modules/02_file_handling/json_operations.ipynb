{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON File Operations\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "- Read and write JSON files using Python's json module\n",
    "- Parse nested JSON structures effectively\n",
    "- Handle JSON parsing exceptions and errors\n",
    "- Work with JSON Lines (JSONL) format\n",
    "- Transform and manipulate JSON data for data engineering tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic JSON Reading and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List, Any, Union, Optional\n",
    "import os\n",
    "\n",
    "# Create sample JSON data\n",
    "sample_user_data = {\n",
    "    \"user_id\": \"USR001\",\n",
    "    \"name\": \"Alice Johnson\",\n",
    "    \"email\": \"alice.johnson@example.com\",\n",
    "    \"age\": 28,\n",
    "    \"is_active\": True,\n",
    "    \"preferences\": {\n",
    "        \"theme\": \"dark\",\n",
    "        \"notifications\": True,\n",
    "        \"language\": \"en\"\n",
    "    },\n",
    "    \"skills\": [\"Python\", \"SQL\", \"Data Analysis\"],\n",
    "    \"projects\": [\n",
    "        {\n",
    "            \"name\": \"Data Pipeline\",\n",
    "            \"status\": \"completed\",\n",
    "            \"start_date\": \"2024-01-15\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Analytics Dashboard\",\n",
    "            \"status\": \"in_progress\",\n",
    "            \"start_date\": \"2024-02-01\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Sample user data:\")\n",
    "print(json.dumps(sample_user_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON to file\n",
    "def write_json_file(data: Union[Dict[str, Any], List[Any]], filename: str, indent: int = 2) -> bool:\n",
    "    \"\"\"\n",
    "    Write data to JSON file.\n",
    "    \n",
    "    Args:\n",
    "        data: Data to write (dict or list)\n",
    "        filename: Output filename\n",
    "        indent: JSON indentation for readability\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, indent=indent, ensure_ascii=False)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSON file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Write sample data to file\n",
    "success = write_json_file(sample_user_data, 'user_data.json')\n",
    "if success:\n",
    "    print(\"Successfully wrote user_data.json\")\n",
    "    \n",
    "    # Verify file contents\n",
    "    with open('user_data.json', 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        print(\"\\nFile contents:\")\n",
    "        print(content[:200] + \"...\" if len(content) > 200 else content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON from file\n",
    "def read_json_file(filename: str) -> Optional[Union[Dict[str, Any], List[Any]]]:\n",
    "    \"\"\"\n",
    "    Read JSON data from file.\n",
    "    \n",
    "    Args:\n",
    "        filename: JSON file to read\n",
    "    \n",
    "    Returns:\n",
    "        Parsed JSON data or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Invalid JSON in {filename}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Read the JSON file back\n",
    "loaded_data = read_json_file('user_data.json')\n",
    "\n",
    "if loaded_data:\n",
    "    print(\"Successfully loaded JSON data:\")\n",
    "    print(f\"User: {loaded_data['name']}\")\n",
    "    print(f\"Email: {loaded_data['email']}\")\n",
    "    print(f\"Skills: {loaded_data['skills']}\")\n",
    "    print(f\"Number of projects: {len(loaded_data['projects'])}\")\n",
    "    \n",
    "    # Access nested data\n",
    "    theme = loaded_data['preferences']['theme']\n",
    "    print(f\"Preferred theme: {theme}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with JSON Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting between JSON strings and Python objects\n",
    "\n",
    "# Python object to JSON string\n",
    "product_data = {\n",
    "    \"product_id\": \"PRD001\",\n",
    "    \"name\": \"Wireless Headphones\",\n",
    "    \"price\": 99.99,\n",
    "    \"in_stock\": True,\n",
    "    \"categories\": [\"Electronics\", \"Audio\"],\n",
    "    \"specifications\": {\n",
    "        \"battery_life\": \"20 hours\",\n",
    "        \"connectivity\": \"Bluetooth 5.0\",\n",
    "        \"weight\": \"250g\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to JSON string\n",
    "json_string = json.dumps(product_data, indent=2)\n",
    "print(\"Product data as JSON string:\")\n",
    "print(json_string)\n",
    "print(f\"\\nJSON string type: {type(json_string)}\")\n",
    "print(f\"JSON string length: {len(json_string)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON string to Python object\n",
    "json_response = '''\n",
    "{\n",
    "    \"status\": \"success\",\n",
    "    \"data\": {\n",
    "        \"users\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"John Doe\",\n",
    "                \"active\": true\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"name\": \"Jane Smith\",\n",
    "                \"active\": false\n",
    "            }\n",
    "        ],\n",
    "        \"total_count\": 2\n",
    "    },\n",
    "    \"timestamp\": \"2024-01-15T10:30:00Z\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse JSON string\n",
    "try:\n",
    "    parsed_response = json.loads(json_response)\n",
    "    print(\"Parsed JSON response:\")\n",
    "    print(f\"Status: {parsed_response['status']}\")\n",
    "    print(f\"Total users: {parsed_response['data']['total_count']}\")\n",
    "    print(f\"Timestamp: {parsed_response['timestamp']}\")\n",
    "    \n",
    "    # Process users\n",
    "    users = parsed_response['data']['users']\n",
    "    print(\"\\nUsers:\")\n",
    "    for user in users:\n",
    "        status = \"Active\" if user['active'] else \"Inactive\"\n",
    "        print(f\"  {user['name']} (ID: {user['id']}) - {status}\")\n",
    "        \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Nested JSON Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex nested JSON structure\n",
    "company_data = {\n",
    "    \"company\": {\n",
    "        \"name\": \"TechCorp Inc.\",\n",
    "        \"founded\": 2010,\n",
    "        \"headquarters\": {\n",
    "            \"address\": \"123 Tech Street\",\n",
    "            \"city\": \"San Francisco\",\n",
    "            \"state\": \"CA\",\n",
    "            \"country\": \"USA\",\n",
    "            \"coordinates\": {\n",
    "                \"latitude\": 37.7749,\n",
    "                \"longitude\": -122.4194\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"departments\": [\n",
    "        {\n",
    "            \"name\": \"Engineering\",\n",
    "            \"head\": \"Alice Johnson\",\n",
    "            \"employees\": [\n",
    "                {\n",
    "                    \"id\": \"ENG001\",\n",
    "                    \"name\": \"Bob Wilson\",\n",
    "                    \"role\": \"Senior Developer\",\n",
    "                    \"skills\": [\"Python\", \"JavaScript\", \"SQL\"],\n",
    "                    \"projects\": [\n",
    "                        {\"name\": \"API Gateway\", \"status\": \"completed\"},\n",
    "                        {\"name\": \"Data Pipeline\", \"status\": \"in_progress\"}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"ENG002\",\n",
    "                    \"name\": \"Carol Davis\",\n",
    "                    \"role\": \"Data Engineer\",\n",
    "                    \"skills\": [\"Python\", \"SQL\", \"Apache Spark\"],\n",
    "                    \"projects\": [\n",
    "                        {\"name\": \"ETL Pipeline\", \"status\": \"completed\"}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Marketing\",\n",
    "            \"head\": \"David Brown\",\n",
    "            \"employees\": [\n",
    "                {\n",
    "                    \"id\": \"MKT001\",\n",
    "                    \"name\": \"Eve Miller\",\n",
    "                    \"role\": \"Marketing Specialist\",\n",
    "                    \"skills\": [\"Digital Marketing\", \"Analytics\"],\n",
    "                    \"projects\": [\n",
    "                        {\"name\": \"Campaign Analysis\", \"status\": \"in_progress\"}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save complex data\n",
    "write_json_file(company_data, 'company_data.json')\n",
    "print(\"Created complex company data JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely access nested JSON data\n",
    "def get_nested_value(data: Dict[str, Any], keys: List[str], default: Any = None) -> Any:\n",
    "    \"\"\"\n",
    "    Safely access nested dictionary values.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary to search\n",
    "        keys: List of keys to traverse\n",
    "        default: Default value if path doesn't exist\n",
    "    \n",
    "    Returns:\n",
    "        Value at nested path or default\n",
    "    \"\"\"\n",
    "    current = data\n",
    "    for key in keys:\n",
    "        if isinstance(current, dict) and key in current:\n",
    "            current = current[key]\n",
    "        else:\n",
    "            return default\n",
    "    return current\n",
    "\n",
    "# Load and analyze complex data\n",
    "company = read_json_file('company_data.json')\n",
    "\n",
    "if company:\n",
    "    # Access nested company information\n",
    "    company_name = get_nested_value(company, ['company', 'name'])\n",
    "    city = get_nested_value(company, ['company', 'headquarters', 'city'])\n",
    "    latitude = get_nested_value(company, ['company', 'headquarters', 'coordinates', 'latitude'])\n",
    "    \n",
    "    print(f\"Company: {company_name}\")\n",
    "    print(f\"Location: {city}\")\n",
    "    print(f\"Latitude: {latitude}\")\n",
    "    \n",
    "    # Process departments and employees\n",
    "    departments = company.get('departments', [])\n",
    "    print(f\"\\nDepartments: {len(departments)}\")\n",
    "    \n",
    "    for dept in departments:\n",
    "        dept_name = dept.get('name', 'Unknown')\n",
    "        head = dept.get('head', 'Unknown')\n",
    "        employees = dept.get('employees', [])\n",
    "        \n",
    "        print(f\"\\n{dept_name} Department:\")\n",
    "        print(f\"  Head: {head}\")\n",
    "        print(f\"  Employees: {len(employees)}\")\n",
    "        \n",
    "        # List employees and their skills\n",
    "        for emp in employees:\n",
    "            name = emp.get('name', 'Unknown')\n",
    "            role = emp.get('role', 'Unknown')\n",
    "            skills = emp.get('skills', [])\n",
    "            projects = emp.get('projects', [])\n",
    "            \n",
    "            print(f\"    {name} ({role})\")\n",
    "            print(f\"      Skills: {', '.join(skills)}\")\n",
    "            print(f\"      Projects: {len(projects)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. JSON Lines (JSONL) Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Lines format - one JSON object per line\n",
    "# This is common for streaming data and log files\n",
    "\n",
    "# Create sample JSONL data\n",
    "log_entries = [\n",
    "    {\"timestamp\": \"2024-01-15T10:00:00Z\", \"level\": \"INFO\", \"message\": \"Application started\", \"user_id\": None},\n",
    "    {\"timestamp\": \"2024-01-15T10:01:00Z\", \"level\": \"INFO\", \"message\": \"User login\", \"user_id\": \"USR001\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:02:00Z\", \"level\": \"WARNING\", \"message\": \"High memory usage\", \"user_id\": None},\n",
    "    {\"timestamp\": \"2024-01-15T10:03:00Z\", \"level\": \"ERROR\", \"message\": \"Database connection failed\", \"user_id\": \"USR002\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:04:00Z\", \"level\": \"INFO\", \"message\": \"User logout\", \"user_id\": \"USR001\"}\n",
    "]\n",
    "\n",
    "# Write JSONL file\n",
    "def write_jsonl_file(data: List[Dict[str, Any]], filename: str) -> bool:\n",
    "    \"\"\"\n",
    "    Write data to JSON Lines file.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries to write\n",
    "        filename: Output filename\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            for record in data:\n",
    "                json_line = json.dumps(record, ensure_ascii=False)\n",
    "                file.write(json_line + '\\n')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSONL file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Write log entries to JSONL file\n",
    "success = write_jsonl_file(log_entries, 'application.jsonl')\n",
    "if success:\n",
    "    print(\"Created application.jsonl file\")\n",
    "    \n",
    "    # Show file contents\n",
    "    with open('application.jsonl', 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        print(\"\\nJSONL file contents:\")\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSONL file\n",
    "def read_jsonl_file(filename: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Read JSON Lines file.\n",
    "    \n",
    "    Args:\n",
    "        filename: JSONL file to read\n",
    "    \n",
    "    Returns:\n",
    "        List of parsed JSON objects\n",
    "    \"\"\"\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            for line_num, line in enumerate(file, 1):\n",
    "                line = line.strip()\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    record = json.loads(line)\n",
    "                    records.append(record)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing line {line_num}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "    \n",
    "    return records\n",
    "\n",
    "# Read and analyze log data\n",
    "logs = read_jsonl_file('application.jsonl')\n",
    "\n",
    "print(f\"Loaded {len(logs)} log entries\")\n",
    "\n",
    "# Analyze log levels\n",
    "level_counts = {}\n",
    "user_activities = {}\n",
    "\n",
    "for log in logs:\n",
    "    level = log.get('level', 'UNKNOWN')\n",
    "    user_id = log.get('user_id')\n",
    "    \n",
    "    # Count log levels\n",
    "    level_counts[level] = level_counts.get(level, 0) + 1\n",
    "    \n",
    "    # Track user activities\n",
    "    if user_id:\n",
    "        if user_id not in user_activities:\n",
    "            user_activities[user_id] = []\n",
    "        user_activities[user_id].append(log)\n",
    "\n",
    "print(f\"\\nLog level distribution: {level_counts}\")\n",
    "print(f\"Users with activities: {list(user_activities.keys())}\")\n",
    "\n",
    "# Show user activities\n",
    "for user_id, activities in user_activities.items():\n",
    "    print(f\"\\n{user_id} activities:\")\n",
    "    for activity in activities:\n",
    "        timestamp = activity['timestamp']\n",
    "        message = activity['message']\n",
    "        print(f\"  {timestamp}: {message}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}