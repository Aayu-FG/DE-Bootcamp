{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "- Understand pandas DataFrames and Series\n",
    "- Create DataFrames from various data sources\n",
    "- Perform basic data exploration and inspection\n",
    "- Select, filter, and manipulate data using pandas\n",
    "- Apply fundamental data transformation operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pandas DataStructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Display all columns and rows for better visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# What is pandas?\n",
    "print(\"\\nPandas is a powerful data manipulation library that provides:\")\n",
    "print(\"✓ DataFrame and Series data structures\")\n",
    "print(\"✓ Data cleaning and transformation tools\")\n",
    "print(\"✓ File I/O operations (CSV, JSON, Excel, etc.)\")\n",
    "print(\"✓ Data aggregation and grouping capabilities\")\n",
    "print(\"✓ Time series analysis tools\")\n",
    "print(\"✓ Integration with other data science libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pandas Series (1-dimensional labeled array)\n",
    "print(\"=== Pandas Series ===\")\n",
    "\n",
    "# Series from list\n",
    "temperatures: pd.Series = pd.Series([22.5, 24.1, 23.8, 25.2, 24.7])\n",
    "print(f\"Temperature Series:\\n{temperatures}\")\n",
    "print(f\"Data type: {temperatures.dtype}\")\n",
    "print(f\"Shape: {temperatures.shape}\")\n",
    "\n",
    "# Series with custom index\n",
    "cities: List[str] = ['New York', 'London', 'Tokyo', 'Sydney', 'Paris']\n",
    "temperatures_indexed: pd.Series = pd.Series([22.5, 15.3, 28.1, 18.9, 20.4], index=cities)\n",
    "print(f\"\\nTemperatures by city:\\n{temperatures_indexed}\")\n",
    "\n",
    "# Series from dictionary\n",
    "population_data: Dict[str, int] = {\n",
    "    'New York': 8_400_000,\n",
    "    'London': 9_000_000,\n",
    "    'Tokyo': 14_000_000,\n",
    "    'Sydney': 5_300_000,\n",
    "    'Paris': 2_200_000\n",
    "}\n",
    "\n",
    "population_series: pd.Series = pd.Series(population_data)\n",
    "print(f\"\\nCity populations:\\n{population_series}\")\n",
    "\n",
    "# Basic Series operations\n",
    "print(f\"\\nSeries operations:\")\n",
    "print(f\"Mean temperature: {temperatures_indexed.mean():.2f}°C\")\n",
    "print(f\"Max population: {population_series.max():,}\")\n",
    "print(f\"Cities with population > 8M: {population_series[population_series > 8_000_000].index.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pandas DataFrames (2-dimensional labeled data structure)\n",
    "print(\"=== Pandas DataFrames ===\")\n",
    "\n",
    "# DataFrame from dictionary\n",
    "employee_data: Dict[str, List[Any]] = {\n",
    "    'employee_id': ['EMP001', 'EMP002', 'EMP003', 'EMP004', 'EMP005'],\n",
    "    'name': ['Alice Johnson', 'Bob Smith', 'Charlie Brown', 'Diana Davis', 'Eve Wilson'],\n",
    "    'department': ['Engineering', 'Marketing', 'Sales', 'Engineering', 'HR'],\n",
    "    'salary': [75000, 65000, 70000, 80000, 60000],\n",
    "    'hire_date': ['2022-01-15', '2021-06-01', '2023-03-10', '2020-11-20', '2022-08-05'],\n",
    "    'is_active': [True, True, True, True, True]\n",
    "}\n",
    "\n",
    "df_employees: pd.DataFrame = pd.DataFrame(employee_data)\n",
    "print(f\"Employee DataFrame:\\n{df_employees}\")\n",
    "\n",
    "# DataFrame info\n",
    "print(f\"\\nDataFrame shape: {df_employees.shape}\")\n",
    "print(f\"Column names: {df_employees.columns.tolist()}\")\n",
    "print(f\"Index: {df_employees.index.tolist()}\")\n",
    "print(f\"Data types:\\n{df_employees.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from list of dictionaries (common in data engineering)\n",
    "sales_records: List[Dict[str, Any]] = [\n",
    "    {'transaction_id': 'TXN001', 'customer_id': 'CUST001', 'product': 'Laptop', 'quantity': 1, 'amount': 999.99, 'date': '2024-01-15'},\n",
    "    {'transaction_id': 'TXN002', 'customer_id': 'CUST002', 'product': 'Mouse', 'quantity': 2, 'amount': 59.98, 'date': '2024-01-15'},\n",
    "    {'transaction_id': 'TXN003', 'customer_id': 'CUST001', 'product': 'Keyboard', 'quantity': 1, 'amount': 79.99, 'date': '2024-01-16'},\n",
    "    {'transaction_id': 'TXN004', 'customer_id': 'CUST003', 'product': 'Monitor', 'quantity': 1, 'amount': 299.99, 'date': '2024-01-16'},\n",
    "    {'transaction_id': 'TXN005', 'customer_id': 'CUST002', 'product': 'Webcam', 'quantity': 1, 'amount': 89.99, 'date': '2024-01-17'}\n",
    "]\n",
    "\n",
    "df_sales: pd.DataFrame = pd.DataFrame(sales_records)\n",
    "print(f\"Sales DataFrame:\\n{df_sales}\")\n",
    "\n",
    "# Convert date column to datetime\n",
    "df_sales['date'] = pd.to_datetime(df_sales['date'])\n",
    "print(f\"\\nAfter date conversion:\\n{df_sales.dtypes}\")\n",
    "\n",
    "# DataFrame from numpy array\n",
    "np.random.seed(42)\n",
    "random_data: np.ndarray = np.random.randn(5, 3)\n",
    "df_random: pd.DataFrame = pd.DataFrame(\n",
    "    random_data, \n",
    "    columns=['A', 'B', 'C'],\n",
    "    index=[f'Row_{i}' for i in range(1, 6)]\n",
    ")\n",
    "print(f\"\\nDataFrame from NumPy array:\\n{df_random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more comprehensive dataset for exploration\n",
    "def create_sample_dataset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a comprehensive sample dataset for exploration.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with sample business data\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_records = 100\n",
    "    \n",
    "    # Generate sample data\n",
    "    data = {\n",
    "        'customer_id': [f'CUST{i:04d}' for i in range(1, n_records + 1)],\n",
    "        'age': np.random.randint(18, 80, n_records),\n",
    "        'gender': np.random.choice(['M', 'F', 'Other'], n_records, p=[0.45, 0.45, 0.1]),\n",
    "        'city': np.random.choice(['New York', 'London', 'Tokyo', 'Sydney', 'Paris'], n_records),\n",
    "        'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home', 'Sports'], n_records),\n",
    "        'purchase_amount': np.round(np.random.uniform(10, 1000, n_records), 2),\n",
    "        'discount_percent': np.round(np.random.uniform(0, 25, n_records), 1),\n",
    "        'is_premium': np.random.choice([True, False], n_records, p=[0.3, 0.7]),\n",
    "        'purchase_date': pd.date_range('2024-01-01', periods=n_records, freq='D')[:n_records]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add some missing values for realistic data\n",
    "    missing_indices = np.random.choice(df.index, size=5, replace=False)\n",
    "    df.loc[missing_indices, 'discount_percent'] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create sample dataset\n",
    "df_sample: pd.DataFrame = create_sample_dataset()\n",
    "print(f\"Sample dataset created with {len(df_sample)} records\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential DataFrame inspection methods\n",
    "print(\"=== DataFrame Inspection ===\")\n",
    "\n",
    "# Basic information\n",
    "print(f\"Shape: {df_sample.shape}\")\n",
    "print(f\"\\nColumn names: {df_sample.columns.tolist()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df_sample.dtypes)\n",
    "\n",
    "# Memory usage\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(df_sample.memory_usage(deep=True))\n",
    "\n",
    "# Info method - comprehensive overview\n",
    "print(f\"\\nDataFrame info:\")\n",
    "df_sample.info()\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\nStatistical summary:\")\n",
    "print(df_sample.describe())\n",
    "\n",
    "# Summary for non-numeric columns\n",
    "print(f\"\\nNon-numeric column summary:\")\n",
    "print(df_sample.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data analysis\n",
    "print(\"=== Missing Data Analysis ===\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_counts = df_sample.isnull().sum()\n",
    "print(f\"Missing values per column:\")\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Missing value percentage\n",
    "missing_percentage = (df_sample.isnull().sum() / len(df_sample)) * 100\n",
    "print(f\"\\nMissing value percentages:\")\n",
    "print(missing_percentage[missing_percentage > 0])\n",
    "\n",
    "# Unique values analysis\n",
    "print(f\"\\n=== Unique Values Analysis ===\")\n",
    "for column in df_sample.columns:\n",
    "    unique_count = df_sample[column].nunique()\n",
    "    print(f\"{column}: {unique_count} unique values\")\n",
    "\n",
    "# Value counts for categorical columns\n",
    "categorical_columns = ['gender', 'city', 'product_category']\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\n{col} distribution:\")\n",
    "    print(df_sample[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Selection and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "print(\"=== Column Selection ===\")\n",
    "\n",
    "# Select single column (returns Series)\n",
    "customer_ids: pd.Series = df_sample['customer_id']\n",
    "print(f\"Customer IDs (first 5): {customer_ids.head().tolist()}\")\n",
    "\n",
    "# Select single column (returns DataFrame)\n",
    "customer_ids_df: pd.DataFrame = df_sample[['customer_id']]\n",
    "print(f\"\\nCustomer IDs as DataFrame shape: {customer_ids_df.shape}\")\n",
    "\n",
    "# Select multiple columns\n",
    "customer_info: pd.DataFrame = df_sample[['customer_id', 'age', 'gender', 'city']]\n",
    "print(f\"\\nCustomer info (first 3 rows):\")\n",
    "print(customer_info.head(3))\n",
    "\n",
    "# Select columns by data type\n",
    "numeric_columns: pd.DataFrame = df_sample.select_dtypes(include=[np.number])\n",
    "print(f\"\\nNumeric columns: {numeric_columns.columns.tolist()}\")\n",
    "\n",
    "categorical_columns_df: pd.DataFrame = df_sample.select_dtypes(include=['object'])\n",
    "print(f\"Categorical columns: {categorical_columns_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row selection and filtering\n",
    "print(\"=== Row Selection and Filtering ===\")\n",
    "\n",
    "# Select rows by index\n",
    "first_5_rows: pd.DataFrame = df_sample.iloc[:5]\n",
    "print(f\"First 5 rows shape: {first_5_rows.shape}\")\n",
    "\n",
    "# Select specific rows by index\n",
    "specific_rows: pd.DataFrame = df_sample.iloc[[0, 2, 4, 6, 8]]\n",
    "print(f\"\\nSpecific rows (0,2,4,6,8):\")\n",
    "print(specific_rows[['customer_id', 'age', 'purchase_amount']])\n",
    "\n",
    "# Boolean filtering\n",
    "print(f\"\\n=== Boolean Filtering ===\")\n",
    "\n",
    "# Filter by single condition\n",
    "high_value_customers: pd.DataFrame = df_sample[df_sample['purchase_amount'] > 500]\n",
    "print(f\"High-value customers (>$500): {len(high_value_customers)} records\")\n",
    "\n",
    "# Filter by multiple conditions\n",
    "premium_electronics: pd.DataFrame = df_sample[\n",
    "    (df_sample['is_premium'] == True) & \n",
    "    (df_sample['product_category'] == 'Electronics')\n",
    "]\n",
    "print(f\"Premium electronics customers: {len(premium_electronics)} records\")\n",
    "\n",
    "# Filter using isin() method\n",
    "major_cities: pd.DataFrame = df_sample[df_sample['city'].isin(['New York', 'London', 'Tokyo'])]\n",
    "print(f\"Customers in major cities: {len(major_cities)} records\")\n",
    "\n",
    "# Filter by string contains\n",
    "cust_001_to_010: pd.DataFrame = df_sample[df_sample['customer_id'].str.contains('CUST000')]\n",
    "print(f\"Customers CUST0001-CUST0009: {len(cust_001_to_010)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced selection with loc and iloc\n",
    "print(\"=== Advanced Selection with loc and iloc ===\")\n",
    "\n",
    "# loc: label-based selection\n",
    "# Select specific rows and columns\n",
    "subset_loc: pd.DataFrame = df_sample.loc[0:4, ['customer_id', 'age', 'purchase_amount']]\n",
    "print(f\"Using loc (rows 0-4, specific columns):\")\n",
    "print(subset_loc)\n",
    "\n",
    "# iloc: integer position-based selection\n",
    "subset_iloc: pd.DataFrame = df_sample.iloc[0:5, [0, 1, 5]]  # First 5 rows, columns 0, 1, 5\n",
    "print(f\"\\nUsing iloc (rows 0-4, columns 0,1,5):\")\n",
    "print(subset_iloc)\n",
    "\n",
    "# Conditional selection with loc\n",
    "young_customers: pd.DataFrame = df_sample.loc[\n",
    "    df_sample['age'] < 30, \n",
    "    ['customer_id', 'age', 'city', 'purchase_amount']\n",
    "]\n",
    "print(f\"\\nYoung customers (<30 years): {len(young_customers)} records\")\n",
    "print(young_customers.head())\n",
    "\n",
    "# Query method for complex filtering\n",
    "query_result: pd.DataFrame = df_sample.query(\n",
    "    'age >= 25 and age <= 45 and purchase_amount > 100'\n",
    ")\n",
    "print(f\"\\nQuery result (age 25-45, amount >$100): {len(query_result)} records\")\n",
    "print(query_result[['customer_id', 'age', 'purchase_amount']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new columns\n",
    "print(\"=== Adding New Columns ===\")\n",
    "\n",
    "# Create a copy for manipulation\n",
    "df_work: pd.DataFrame = df_sample.copy()\n",
    "\n",
    "# Add calculated column\n",
    "df_work['discount_amount'] = df_work['purchase_amount'] * (df_work['discount_percent'] / 100)\n",
    "df_work['final_amount'] = df_work['purchase_amount'] - df_work['discount_amount']\n",
    "\n",
    "print(f\"Added discount_amount and final_amount columns\")\n",
    "print(df_work[['purchase_amount', 'discount_percent', 'discount_amount', 'final_amount']].head())\n",
    "\n",
    "# Add categorical column based on conditions\n",
    "def categorize_age(age: int) -> str:\n",
    "    if age < 25:\n",
    "        return 'Young'\n",
    "    elif age < 45:\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "df_work['age_group'] = df_work['age'].apply(categorize_age)\n",
    "\n",
    "print(f\"\\nAge group distribution:\")\n",
    "print(df_work['age_group'].value_counts())\n",
    "\n",
    "# Add column using numpy where\n",
    "df_work['customer_tier'] = np.where(\n",
    "    df_work['is_premium'], \n",
    "    'Premium', \n",
    "    np.where(df_work['purchase_amount'] > 200, 'Gold', 'Standard')\n",
    ")\n",
    "\n",
    "print(f\"\\nCustomer tier distribution:\")\n",
    "print(df_work['customer_tier'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying existing columns\n",
    "print(\"=== Modifying Existing Columns ===\")\n",
    "\n",
    "# String operations\n",
    "df_work['city_upper'] = df_work['city'].str.upper()\n",
    "df_work['customer_code'] = df_work['customer_id'].str.replace('CUST', 'C')\n",
    "\n",
    "print(f\"String transformations:\")\n",
    "print(df_work[['city', 'city_upper', 'customer_id', 'customer_code']].head())\n",
    "\n",
    "# Numeric operations\n",
    "df_work['purchase_amount_rounded'] = df_work['purchase_amount'].round(0)\n",
    "df_work['age_normalized'] = (df_work['age'] - df_work['age'].min()) / (df_work['age'].max() - df_work['age'].min())\n",
    "\n",
    "print(f\"\\nNumeric transformations:\")\n",
    "print(df_work[['purchase_amount', 'purchase_amount_rounded', 'age', 'age_normalized']].head())\n",
    "\n",
    "# Date operations\n",
    "df_work['purchase_year'] = df_work['purchase_date'].dt.year\n",
    "df_work['purchase_month'] = df_work['purchase_date'].dt.month\n",
    "df_work['purchase_day_name'] = df_work['purchase_date'].dt.day_name()\n",
    "\n",
    "print(f\"\\nDate transformations:\")\n",
    "print(df_work[['purchase_date', 'purchase_year', 'purchase_month', 'purchase_day_name']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and ranking\n",
    "print(\"=== Sorting and Ranking ===\")\n",
    "\n",
    "# Sort by single column\n",
    "df_sorted_amount: pd.DataFrame = df_work.sort_values('purchase_amount', ascending=False)\n",
    "print(f\"Top 5 purchases by amount:\")\n",
    "print(df_sorted_amount[['customer_id', 'purchase_amount', 'product_category']].head())\n",
    "\n",
    "# Sort by multiple columns\n",
    "df_sorted_multi: pd.DataFrame = df_work.sort_values(['city', 'purchase_amount'], ascending=[True, False])\n",
    "print(f\"\\nSorted by city (asc) then amount (desc):\")\n",
    "print(df_sorted_multi[['customer_id', 'city', 'purchase_amount']].head(10))\n",
    "\n",
    "# Add ranking columns\n",
    "df_work['amount_rank'] = df_work['purchase_amount'].rank(ascending=False, method='dense')\n",
    "df_work['age_percentile'] = df_work['age'].rank(pct=True)\n",
    "\n",
    "print(f\"\\nRanking examples:\")\n",
    "top_purchases = df_work.nsmallest(5, 'amount_rank')\n",
    "print(top_purchases[['customer_id', 'purchase_amount', 'amount_rank', 'age', 'age_percentile']])\n",
    "\n",
    "# Group ranking\n",
    "df_work['city_amount_rank'] = df_work.groupby('city')['purchase_amount'].rank(ascending=False, method='dense')\n",
    "print(f\"\\nTop purchase in each city:\")\n",
    "top_by_city = df_work[df_work['city_amount_rank'] == 1]\n",
    "print(top_by_city[['customer_id', 'city', 'purchase_amount', 'city_amount_rank']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with missing data\n",
    "print(\"=== Handling Missing Data ===\")\n",
    "\n",
    "# Check current missing data\n",
    "print(f\"Missing values in discount_percent: {df_work['discount_percent'].isnull().sum()}\")\n",
    "\n",
    "# Different strategies for handling missing data\n",
    "\n",
    "# 1. Fill with a constant value\n",
    "df_fill_zero = df_work.copy()\n",
    "df_fill_zero['discount_percent'] = df_fill_zero['discount_percent'].fillna(0)\n",
    "print(f\"\\nAfter filling with 0: {df_fill_zero['discount_percent'].isnull().sum()} missing values\")\n",
    "\n",
    "# 2. Fill with mean/median\n",
    "df_fill_mean = df_work.copy()\n",
    "mean_discount = df_fill_mean['discount_percent'].mean()\n",
    "df_fill_mean['discount_percent'] = df_fill_mean['discount_percent'].fillna(mean_discount)\n",
    "print(f\"After filling with mean ({mean_discount:.2f}): {df_fill_mean['discount_percent'].isnull().sum()} missing values\")\n",
    "\n",
    "# 3. Forward fill (use previous value)\n",
    "df_ffill = df_work.copy()\n",
    "df_ffill['discount_percent'] = df_ffill['discount_percent'].fillna(method='ffill')\n",
    "print(f\"After forward fill: {df_ffill['discount_percent'].isnull().sum()} missing values\")\n",
    "\n",
    "# 4. Fill based on group statistics\n",
    "df_group_fill = df_work.copy()\n",
    "df_group_fill['discount_percent'] = df_group_fill.groupby('product_category')['discount_percent'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "print(f\"After group-based fill: {df_group_fill['discount_percent'].isnull().sum()} missing values\")\n",
    "\n",
    "# 5. Drop rows with missing values\n",
    "df_dropna = df_work.dropna(subset=['discount_percent'])\n",
    "print(f\"\\nOriginal rows: {len(df_work)}, After dropping NaN: {len(df_dropna)}\")\n",
    "\n",
    "# Show comparison of different strategies\n",
    "comparison_data = {\n",
    "    'Original': df_work['discount_percent'].iloc[:10],\n",
    "    'Fill_Zero': df_fill_zero['discount_percent'].iloc[:10],\n",
    "    'Fill_Mean': df_fill_mean['discount_percent'].iloc[:10],\n",
    "    'Group_Fill': df_group_fill['discount_percent'].iloc[:10]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(f\"\\nComparison of missing data strategies (first 10 rows):\")\n",
    "print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}